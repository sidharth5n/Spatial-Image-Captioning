from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import numpy as np
import time
import misc.utils as utils
from collections import OrderedDict
import torch

import sys
sys.path.append("cider")
from pyciderevalcap.ciderD.ciderD import CiderD
sys.path.append("coco-caption")
from pycocoevalcap.bleu.bleu import Bleu

CiderD_scorer = None
Bleu_scorer = None
#CiderD_scorer = CiderD(df='corpus')

def init_scorer(cached_tokens):
    global CiderD_scorer
    CiderD_scorer = CiderD_scorer or CiderD(df=cached_tokens)
    global Bleu_scorer
    Bleu_scorer = Bleu_scorer or Bleu(4)

def array_to_str(arr):
    out = ''
    for i in range(len(arr)):
        out += str(arr[i]) + ' '
        if arr[i] == 0:
            break
    return out.strip()

def get_self_critical_reward(model, att_feats, att_masks, boxes, gts, gen_result, opt):
    """
    Computes the self critical reward for the generated sequence.

    Parameters
    ----------
    att_feats  : torch.tensor of shape (B, L, D)
                 Output of last conv layer of CNN or bottom-up features
    att_masks  : torch.tensor of shape (B, L)
                 Attention mask.
    boxes      : torch.tensor of shape (B, L, 4)
                 Coordinates of bounding boxes.
    gts        : list
                 Each element is a numpy.ndarray containing all the ground truth
                 sequences.
    gen_result : torch.tensor of shape (B, T)
                 Sequences generated by model using sampling
    opt        : Parameters

    Returns
    -------
    rewards    : torch.tensor of shape (B, T)
                 Self critical reward
    """
    batch_size = gen_result.size(0)# batch_size = sample_size * seq_per_img
    seq_per_img = batch_size // len(gts)

    # get greedy decoding baseline
    model.eval()
    with torch.no_grad():
        greedy_res, _ = model(att_feats, att_masks, boxes, mode = 'sample')
    model.train()

    res = OrderedDict()

    gen_result = gen_result.data.cpu().numpy()
    greedy_res = greedy_res.data.cpu().numpy()
    for i in range(batch_size):
        res[i] = [array_to_str(gen_result[i])]
    for i in range(batch_size):
        res[batch_size + i] = [array_to_str(greedy_res[i])]

    gts_ = OrderedDict()
    for i in range(len(gts)):
        gts_[i] = [array_to_str(gts[i][j]) for j in range(len(gts[i]))]

    res_ = [{'image_id':i, 'caption': res[i]} for i in range(2 * batch_size)]
    res__ = {i: res[i] for i in range(2 * batch_size)}
    gts_ = {i: gts_[i % batch_size // seq_per_img] for i in range(2 * batch_size)}
    if opt.cider_reward_weight > 0:
        _, cider_scores = CiderD_scorer.compute_score(gts_, res_)
        print('Cider scores:', _)
    else:
        cider_scores = 0
    if opt.bleu_reward_weight > 0:
        _, bleu_scores = Bleu_scorer.compute_score(gts_, res__)
        bleu_scores = np.array(bleu_scores[3])
        print('Bleu scores:', _[3])
    else:
        bleu_scores = 0
    scores = opt.cider_reward_weight * cider_scores + opt.bleu_reward_weight * bleu_scores

    scores = scores[:batch_size] - scores[batch_size:]

    rewards = np.repeat(scores[:, np.newaxis], gen_result.shape[1], 1)

    return torch.from_numpy(rewards).to(att_feats)
